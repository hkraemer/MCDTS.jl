<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · MCDTS</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">MCDTS</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com//blob/master/docs/src/ref.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="MCDTS.AbstractTreeElement" href="#MCDTS.AbstractTreeElement"><code>MCDTS.AbstractTreeElement</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">The MCDTS algorithm is implemented as a tree with different kind types encoding
the leafs and the root of the tree. AbstractTreeElement is the abstract type of
these types.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.CCM_ρ" href="#MCDTS.CCM_ρ"><code>MCDTS.CCM_ρ</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CCM_ρ &lt;: AbstractLoss

Constructor for the CCM_ρ loss function (correlation coefficient of the
convergent cross mapping) based on Sugihara et al.[^Sugihara2012], see also
[`ccm`](@ref). In this case MCDTS tries to maximize the correlation coefficient
of the convergent cross mapping from the input `data` and `Y_CCM`, the time
series CCM should cross map to from `data` (see [`mcdts_embedding`](@ref)).

## Fieldnames
* `timeseries`: The time series CCM should cross map to.
* `threshold::Float`: A threshold for the sufficient correlation of the
  cross-mapped values and the true values from `Y_CMM` for the current embedding.
  When the correlation coefficient exeeds this threshold in an embedding cycle
  the embedding stops.

## Defaults
* When calling `CCM_ρ(timeseries)`, a CCM_ρ-object is created, storing
  `timeseries`, which is considered to be causally depended and the
  `threshold=1` is used, i.e. no threshold, since the correlation coefficient
  can not exceed 1.

[^Sugihara2012]: Sugihara et al., [Detecting Causality in Complex Ecosystems. Science 338, 6106, 496-500](https://doi.org/10.1126/science.1227079)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.Continuity_function" href="#MCDTS.Continuity_function"><code>MCDTS.Continuity_function</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Continuity_function &lt;: AbstractDelayPreselection

Constructor for the continuity function `⟨ε★⟩` by Pecora et al.[^Pecora2007],
see [`pecora`](@ref).

## Fieldnames
* `K::Int`: the amount of nearest neighbors in the δ-ball. Must be at
  least 8 (in order to gurantee a valid statistic). `⟨ε★⟩` is computed taking
  the minimum result over all `k ∈ K` (read algorithm description in [`pecora`](@ref)).
* `samplesize::Real`: determine the fraction of all phase space points
  to be considered (fiducial points v) to average ε★ to produce `⟨ε★⟩`.
* `α::Real = 0.05`: The significance level for obtaining the continuity statistic
* `p::Real = 0.5`: The p-parameter for the binomial distribution used for the
  computation of the continuity statistic ⟨ε★⟩.

## Defaults
* When calling `Continuity_function()` a Continuity_function-object is constructed
  with `K=13`, `samplesize=1.`, `α=0.05` and `p=0.5`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.FNN_statistic" href="#MCDTS.FNN_statistic"><code>MCDTS.FNN_statistic</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FNN_statistic &lt;: AbstractLoss

Constructor for the FNN-statistic loss function (false nearest neighbor) based
on Hegger &amp; Kantz [^Hegger1999].

## Fieldnames
* `threshold::Float`: A threshold for the tolerable cumulative FNN decrease
  for the current embedding. When the fraction of FNNs fall below this threshold
  in an embedding cycle the embedding stops.
* `r::Float`: The FNN-distance-expansion threshold (typically set to 2).

## Defaults
* When calling `FNN_statistic()`, a FNN_statistic-object is created, which uses no
  threshold and uses the FNN-inter threshold `r=2`.
* When calling `FNN_statistic(threshold)`, a FNN_statistic-object is created, which uses
  the given `threshold` and uses the FNN-inter threshold `r=2`.

[^Hegger1999]: Hegger &amp; Kantz, [Improved false nearest neighbor method to detect determinism in time series data. Physical Review E 60, 4970](https://doi.org/10.1103/PhysRevE.60.4970).</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.L_statistic" href="#MCDTS.L_statistic"><code>MCDTS.L_statistic</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">L_statistic &lt;: AbstractLoss

Constructor for the L-statistic loss function based on Uzal et al.[^Uzal2011]. Here
we consider the decrease of the L-statistic `ΔL` in between embedding cycles,
according to Kraemer et al.[^Kraemer2021] ([`pecuzal_embedding`](@ref)).

## Fieldnames
* `threshold::Float`: A threshold for the tolerable `ΔL` decrease for the current
  embedding. When `ΔL` exceeds this threshold in an embedding cycle the embedding
  stops. Note that `ΔL` is a negative value therefore `threshold` must be a small
  negative number.
* `KNN::Int`: the amount of nearest neighbors considered, in order to compute the
 L-statistic, in particular `σ_k^2` (read algorithm description [`uzal_cost`]@ref).
* `tws::AbstractRange{Int}`: Customization of the sampling of the different time horizons
  (T&#39;s), when computing Uzal&#39;s L-statistics. Here any kind of integer ranges (starting at 2)
  are allowed.

## Defaults
* When calling `L_statistic()`, a L_statistic-object is created, which uses no
  threshold and consideres 3 nearest neighbors for time horizons `tws=2:100`.
* When calling `L_statistic(threshold)`, a L_statistic-object is created, which uses
  the given `threshold` and consideres 3 nearest neighbors for time horizons `tws=2:100`.
* When calling `L_statistic(threshold,KNN)`, a L_statistic-object is created, which uses
  the given `threshold`, consideres `KNN` nearest neighbors for time horizons `tws=2:100`.

[^Kraemer2021]: Kraemer, K.H., Datseris, G., Kurths, J., Kiss, I.Z., Ocampo-Espindola, Marwan, N. (2021). [A unified and automated approach to attractor reconstruction. New Journal of Physics 23(3), 033017](https://iopscience.iop.org/article/10.1088/1367-2630/abe336).

[^Uzal2011]: Uzal, L. C., Grinblat, G. L., Verdes, P. F. (2011). [Optimal reconstruction of dynamical systems: A noise amplification approach. Physical Review E 84, 016223](https://doi.org/10.1103/PhysRevE.84.016223).</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.MCDTSOptimGoal" href="#MCDTS.MCDTSOptimGoal"><code>MCDTS.MCDTSOptimGoal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MCDTSOptimGoal &lt;: AbstractMCDTSOptimGoal

Constructor, which handles the loss-/objective function `Γ` and the delay
pre-selection statistic `Λ` MCDTS uses.

## Fieldnames
* `Γ::AbstractLoss`: Chosen loss-function, see the so far available
  [`L_statistic`](@ref), [`FNN_statistic`](@ref), [`CCM_ρ`](@ref) and
  [`Prediction_error`](@ref).
* `Λ::AbstractDelayPreselection`: Chosen delay Pre-selection method, see the so
  far available [`Continuity_function`](@ref) and [`Range_function`](@ref).

## Defaults
* TBD</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.MCDTSpredictionType" href="#MCDTS.MCDTSpredictionType"><code>MCDTS.MCDTSpredictionType</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MCDTSpredictionType &lt;: AbstractMCDTSpredictionType

Constructor, which determines the way how predictions are made technically.

## Fieldnames
* `loss::AbstractPredictionLoss`: Indicates the way of computing the prediction error.
   See [`PredictionLoss`](@ref) for information on how to construct this object.
* `method::AbstractPredictionMethod`: The method based on the state space reconstruction,
   which makes the actual prediction. See [`local_model`](@ref)

## Default settings
* When calling `MCDTSpredictionType()` a MCDTSpredictionType-object is constructed
  with a `local_zeroth`-predictor [`local_model`](@ref), using 2 nearest neighbors
  and a 1-step-ahead-prediction. The loss-function is the root mean squared prediction
  error over all components [`PredictionLoss`](@ref).</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.Node" href="#MCDTS.Node"><code>MCDTS.Node</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">mutable struct Node{T}

A node of the tree. Each node contains its children and information about the current embedding.

## Fieldnames:
* `τ::Int`: The delay value of this node
* `L::T`: The value of the cumulative ΔL statistic at this node
* `τs::Array{Int,1}`: The complete vector with all τs chosen along this path up until this node
* `ts::Array{Int,1}`: The complex vector which of the possibly multivariate time series is used at each embedding step i
* `children::Union{Array{Node,1},Nothing}`: The children of this node
* `temp::S`: additional &quot;work&quot;/&quot;temporary&quot; array/field that can be manipulated and saved by the optimization e.g. to reuse prior computations</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.PredictionLoss" href="#MCDTS.PredictionLoss"><code>MCDTS.PredictionLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PredictionLoss &lt;: AbstractPredictionLoss

Constructor, which indicates the way of computing the prediction error. This
object is used for the constructor, which determines the way how predictions are
made methodologically [`MCDTSpredictionType`](@ref).

## Fieldnames
* `type::Int` is an integer, which encodes the type of prediction error:
* For `type = 1` the root mean squared prediction error over the first component,
  i.e. the timeseries, which needs to be predicted, is used. (default)
* For `type = 2` the root mean squared prediction error over all components
  (dimensionality of the state space) is used.
* For `type = 3` the mean Kullback-Leibler Distance of the predicted and the true
  values of the first component, i.e. the timeseries, which needs to be predicted, is used.
* For `type = 4` the mean Kullback-Leibler Distance of the predicted and the true
  values over all components (dimensionality of the state space) is used.

## Default settings
* When calling `PredictionLoss()` a PredictionLoss-object is constructed with
  fieldname `type = 1` (≡root mean squared prediction error over all components)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.Prediction_error" href="#MCDTS.Prediction_error"><code>MCDTS.Prediction_error</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Prediction_error &lt;: AbstractLoss

Constructor for the Prediction_error loss function.

## Fieldnames
* `PredictionType::MCDTSpredictionType`: Determines the prediction type by
  setting a prediction-method and the way the prediction error is measured,
  see [`MCDTSpredictionType`](@ref).
* `threshold::Float`: A threshold for the sufficient minimum prediction error
  for the current embedding. When the prediction error, specified in
  `PredictionType`, falls below this threshold in an embedding cycle the
  embedding stops.

## Defaults
* When calling `Prediction_error()`, a Prediction_error-object is created,
  which uses the threshold 0, i.e. no threshold and a zeroth-order predictor
  (see [`MCDTSpredictionType`](@ref), [`PredictionLoss`](@ref) &amp;
  [`local_model`](@ref))</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.Range_function" href="#MCDTS.Range_function"><code>MCDTS.Range_function</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Range_function &lt;: AbstractDelayPreselection

Constructor for a range of possible delay values. In this case there is
actually no &quot;pre-selection&quot; of delay, but rather all possible delays, given
in the input `τs` (see, [`mcdts_embedding`](@ref)) are considered. This can significantly affect the
computation time. There are no fieldnames, simply construct by typing
`RangeFunction()`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.Root" href="#MCDTS.Root"><code>MCDTS.Root</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">mutable struct Root &lt;: AbstractTreeElement

The &#39;start&#39;/root of Tree. Each node contains its children. The root contains the starting branches/nodes.
For initialization type `r = Root()`.

## Fieldnames:
* `children::Union{Array{Node,1},Nothing}`: The first nodes of the tree.
* `Lmin`; Is the global minimum of the cumulative ΔL statistic found so far.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.local_model" href="#MCDTS.local_model"><code>MCDTS.local_model</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">local_model &lt;: AbstractPredictionMethod

Constructor, which indicates the local state space prediction model.

## Fieldnames
* `method::String`: Could be `&quot;zeroth&quot;` (averaged `Tw`-step-ahead image of the
 `KNN`-nearest neighbors) or `&quot;linear&quot;` (local linear regression on the
 `KNN`-nearest neighbors).
* `KNN::Int`: The number of considered nearest neighbors.
* `Tw::Int` : The prediction horizon in sampling units.

## Default settings
* When calling `local_model()` a local_model-object is constructed with a zeroth
  order prediction scheme, 2 nearest neighbors and a 1-step-ahead prediction.
* When calling `local_model(method)` a local_model-object is constructed with a
  `method`-prediction scheme, 2 nearest neighbors and a 1-step-ahead prediction.
* When calling `local_model(method,KNN)` a local_model-object is constructed with a
 `method`-prediction scheme, `KNN` nearest neighbors and a 1-step-ahead prediction.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.all_neighbors" href="#MCDTS.all_neighbors"><code>MCDTS.all_neighbors</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">all_neighbors(A::Dataset, stype, w = 0) → idxs, dists</code></pre><p>Find the neighbors of all points in <code>A</code> using search type <code>stype</code> (either <a href="@ref"><code>NeighborNumber</code></a> or <a href="@ref"><code>WithinRange</code></a>) and <code>w</code> the <a href="@ref">Theiler window</a>.</p><p>This function is nothing more than a convinience call to <code>Neighborhood.bulksearch</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.ar_process-Union{Tuple{T}, Tuple{T, T, T, Int64}} where T&lt;:Real" href="#MCDTS.ar_process-Union{Tuple{T}, Tuple{T, T, T, Int64}} where T&lt;:Real"><code>MCDTS.ar_process</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Generate data from a AR(1) process for a initial value `u0`, a AR-coefficient
`α` and a white noise scaling parameter `p`. Return a time series of length `N`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.backprop!-Tuple{MCDTS.Root, Any, Any, Any}" href="#MCDTS.backprop!-Tuple{MCDTS.Root, Any, Any, Any}"><code>MCDTS.backprop!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">backprop!(n::Root,τs,ts,L_min)

Backpropagation of the tree spanned by all children in `n` (for this run).
All children-nodes L-values get set to the final value achieved in this run.
This function is ususally called be [`expand!`](@ref).</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.best_embedding-Tuple{MCDTS.Root}" href="#MCDTS.best_embedding-Tuple{MCDTS.Root}"><code>MCDTS.best_embedding</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">best_embedding(r::Root)

Given the root `r` of a tree, return the best embedding in the form of the
final node at the end of the best embedding.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.ccm-Union{Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T}}} where {D, T&lt;:Real}" href="#MCDTS.ccm-Union{Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T}}} where {D, T&lt;:Real}"><code>MCDTS.ccm</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ccm(X, y; kwargs...) → ρ, y_hat

Compute the convergent crossmapping (CCM) (Sugihara et al. 2012) of a
vector time series `X` (an embedded time series `x`) on the time series `y`
NOTE: &#39;X&#39; and &#39;y&#39; must have the same length and you have to make sure that
&#39;y&#39; starts at the same time index as &#39;X&#39; does. - When using [`genembed`](@ref)
with negative delays to construct `X` from `x`, which is mandatory here, then
&#39;y&#39; needs to be shifted by the largest negative delay value, which has been
used to construct `X`.

Returns the correlation coefficient of `y` and its predicted values for `y_hat`,
based on the nearest neighbour structure of `X`.
It is said that &#39;y&#39; causes &#39;x&#39;, if ρ increases with increasing time series
length AND ρ is &quot;quite high&quot;.

Keyword arguments:
*`metric = Euclidean()`: The metric for vector distance computation.
*`w::Int = 1`: The Theiler window in sampling units.
*`lags::Array = [0]`: The lag for the cross mapping, in order to detect time lagged
                      causal relationships. The output ρ is an array of size
                      `length(lags)`, the output Y_hat is the one corresponding
                      to a lag of zero.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.choose_children-Tuple{MCDTS.AbstractTreeElement, Int64, Int64}" href="#MCDTS.choose_children-Tuple{MCDTS.AbstractTreeElement, Int64, Int64}"><code>MCDTS.choose_children</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">choose_children(n::AbstractTreeElement, τ::Int, t:Int)</code></pre><p>Pick one of the children of the tree node <code>n</code> with values <code>τ</code> and <code>t</code>. If there is none, return <code>nothing</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.choose_next_node" href="#MCDTS.choose_next_node"><code>MCDTS.choose_next_node</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">choose_next_node(n::Union{Node,Root}, func, Lmin_global, i_trial::Int=1)

Returns one of the children of based on the function `func(Ls)-&gt;i_node`,
Lmin_global is the best L value so far in the optimization process, if any of
the input Ls to choose from is smaller than it, it is always chosen.
`choose_mode` is only relevant for the first embedding step right now: it
determines if the first step is chosen uniform (`choose_mode==0`) or with the
`func` (`choose_mode==1`).</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.columns" href="#MCDTS.columns"><code>MCDTS.columns</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">columns(dataset) -&gt; x, y, z, ...</code></pre><p>Return the individual columns of the dataset.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_KL_divergence-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T" href="#MCDTS.compute_KL_divergence-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T"><code>MCDTS.compute_KL_divergence</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Compute the Kullback-Leibler-Divergence of the two Vectors `a` and `b`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_abs_err-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T" href="#MCDTS.compute_abs_err-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T"><code>MCDTS.compute_abs_err</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Compute the total absolute error between `prediction` and `reference`</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_costs_from_prediction-Union{Tuple{T}, Tuple{D}, Tuple{MCDTS.AbstractPredictionLoss{1}, DelayEmbeddings.AbstractDataset{D, T}, DelayEmbeddings.AbstractDataset{D, T}, Int64}} where {D, T}" href="#MCDTS.compute_costs_from_prediction-Union{Tuple{T}, Tuple{D}, Tuple{MCDTS.AbstractPredictionLoss{1}, DelayEmbeddings.AbstractDataset{D, T}, DelayEmbeddings.AbstractDataset{D, T}, Int64}} where {D, T}"><code>MCDTS.compute_costs_from_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Compute the in-sample prediction costs based on the loss-metric determined
by PredictionLoss</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_delta_L-Union{Tuple{T}, Tuple{Vector{T}, Vector{Int64}, Int64}} where T" href="#MCDTS.compute_delta_L-Union{Tuple{T}, Tuple{Vector{T}, Vector{Int64}, Int64}} where T"><code>MCDTS.compute_delta_L</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">compute_delta_L(s, τs, (js,) T_max; KNN = 3, w = 1, metric = Euclidean) → ΔL

Compute the overall L-decrease `ΔL` of a given embedding of the time series
`s::Vector` with the delay values `τs` up to a maximum `T`-value `T_max`. We
respect the Theiler window `w`, the chosen `metric` and the number of considered
nearest neighbors `KNN`. It is also possible to compute `ΔL` for a multivariate
input `Y::Dataset`. Then one additionally needs to supply a vector `js`, which
lists the chosen time series corresponding to the given delay values in `τs`.
This is similar to the procedure in [`genembed`]@ref. The computations are based
on z-standardized input for ensuring comparability.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_loss" href="#MCDTS.compute_loss"><code>MCDTS.compute_loss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Compute the loss of a given delay-preselection statistic `dps` and the loss
determined by `optimalg.Γ`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_loss-Union{Tuple{T}, Tuple{D}, Tuple{P}, Tuple{MCDTS.CCM_ρ, MCDTS.AbstractDelayPreselection, Vector{P}, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Int64, Any, Any}} where {P, D, T}" href="#MCDTS.compute_loss-Union{Tuple{T}, Tuple{D}, Tuple{P}, Tuple{MCDTS.CCM_ρ, MCDTS.AbstractDelayPreselection, Vector{P}, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Int64, Any, Any}} where {P, D, T}"><code>MCDTS.compute_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Return the loss based on the negative correlation coefficient for CCM.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_loss-Union{Tuple{T}, Tuple{D}, Tuple{P}, Tuple{MCDTS.FNN_statistic, MCDTS.AbstractDelayPreselection, Vector{P}, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Int64, Any, Any}} where {P, D, T}" href="#MCDTS.compute_loss-Union{Tuple{T}, Tuple{D}, Tuple{P}, Tuple{MCDTS.FNN_statistic, MCDTS.AbstractDelayPreselection, Vector{P}, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Int64, Any, Any}} where {P, D, T}"><code>MCDTS.compute_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Return the loss based on the FNN-statistic `FNN` and indices `max_idx`  for all local maxima in dps</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_loss-Union{Tuple{T}, Tuple{D}, Tuple{P}, Tuple{MCDTS.L_statistic, MCDTS.AbstractDelayPreselection, Vector{P}, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Int64, Any, Any}} where {P, D, T}" href="#MCDTS.compute_loss-Union{Tuple{T}, Tuple{D}, Tuple{P}, Tuple{MCDTS.L_statistic, MCDTS.AbstractDelayPreselection, Vector{P}, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Int64, Any, Any}} where {P, D, T}"><code>MCDTS.compute_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Return the loss based on the maximum decrease of the L-statistic `L_decrease` and corresponding
delay-indices `max_idx` for all local maxima in ε★</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_loss-Union{Tuple{T}, Tuple{D}, Tuple{P}, Tuple{MCDTS.Prediction_error, MCDTS.AbstractDelayPreselection, Vector{P}, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Int64, Any, Any}} where {P, D, T}" href="#MCDTS.compute_loss-Union{Tuple{T}, Tuple{D}, Tuple{P}, Tuple{MCDTS.Prediction_error, MCDTS.AbstractDelayPreselection, Vector{P}, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Int64, Any, Any}} where {P, D, T}"><code>MCDTS.compute_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Return the loss based on a `Tw`-step-ahead local-prediction.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.compute_mse-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T" href="#MCDTS.compute_mse-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T"><code>MCDTS.compute_mse</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Compute the mean squared error between `prediction` and `reference`</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.difference_distribution-Tuple{StatsBase.Histogram, Any}" href="#MCDTS.difference_distribution-Tuple{StatsBase.Histogram, Any}"><code>MCDTS.difference_distribution</code></a> — <span class="docstring-category">Method</span></header><section><div><p>calculate σ(ζ) = ∫ρ(x) ρ(ζ-x) dx , approximating ζ to be in bin start (whole bin counts).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.embed_for_prediction-Union{Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T}, Int64}} where {D, T}" href="#MCDTS.embed_for_prediction-Union{Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T}, Int64}} where {D, T}"><code>MCDTS.embed_for_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">embed_for_prediction(Y::Dataset, x::Vector, τ::Int) → Y_embed

Embeds the trajectory (or Vector) `Y` in an additional dimension, using the time
series `x` and the provided lag `τ`. Here we enforce a causal embedding, meaning
that we shift `x` by the negative values `τ`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.embedding_cycle-Tuple{MCDTS.AbstractMCDTSOptimGoal, Any, Any, Any, Any, Any, Any}" href="#MCDTS.embedding_cycle-Tuple{MCDTS.AbstractMCDTSOptimGoal, Any, Any, Any, Any, Any, Any}"><code>MCDTS.embedding_cycle</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Perform a potential embedding cycle from the multi- or univariate Dataset `Ys`.
Return the possible delays `τ_pot`, the associated time series `ts_pot` and
the corresponding L-statistic-values, `L_pot` for each peak, i.e. for each
(`τ_pot`, `ts_pot`) pair. If `FNN=true`, `L_pot` stores the corresponding
fnn-statistic-values.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.expand!-Union{Tuple{T}, Tuple{DT}, Tuple{D}, Tuple{MCDTS.Root, MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Int64}, Tuple{MCDTS.Root, MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Int64, AbstractRange{DT}}, Tuple{MCDTS.Root, MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Int64, AbstractRange{DT}, Int64}} where {D, DT, T&lt;:Real}" href="#MCDTS.expand!-Union{Tuple{T}, Tuple{DT}, Tuple{D}, Tuple{MCDTS.Root, MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Int64}, Tuple{MCDTS.Root, MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Int64, AbstractRange{DT}}, Tuple{MCDTS.Root, MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Int64, AbstractRange{DT}, Int64}} where {D, DT, T&lt;:Real}"><code>MCDTS.expand!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">expand!(n::Union{Node,Root}, optimalg::AbstractMCDTSOptimGoal, data::Dataset,
                                        w::Int, delays, choose_mode; kwargs...)

This is one single rollout and backprop of the tree. For details please see
the accompanying paper [^Kraemer2021b].

* `n`: Starting node
* `optimalg::AbstractMCDTSOptimGoal`: Determines the delay preselection and
  cost function (see [`MCDTSOptimGoal`](@ref)).
* `data`: data
* `w`: Theiler Window
* `delays = 0:100`: The possible time lags
* `choose_mode::Int=0`: Possibility for different modes of choosing the next
  node based on which trial this is.

## Keyword arguments
* See [`mcdts_embedding`](@ref) for a list of all keywords.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.fnn_embedding_cycle" href="#MCDTS.fnn_embedding_cycle"><code>MCDTS.fnn_embedding_cycle</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">fnn_embedding_cycle(NNdist, NNdistnew, r=2) -&gt; FNNs

Compute the amount of false nearest neighbors `FNNs`, when adding another component
to a given (vector-) time series. This new component is the `τ`-lagged version
of a univariate time series. `NNdist` is storing the distances of the nearest
neighbor for all considered fiducial points and `NNdistnew` is storing the
distances of the nearest neighbor for each fiducial point in one embedding
dimension higher using a given `τ`. The obligatory threshold `r` is by default
set to 2.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.genembed_for_prediction-Union{Tuple{T}, Tuple{Vector{T}, Vector{Int64}}} where T" href="#MCDTS.genembed_for_prediction-Union{Tuple{T}, Tuple{Vector{T}, Vector{Int64}}} where T"><code>MCDTS.genembed_for_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">genembed_for_prediction(Y, τs::Vector (,ts::Vector)) → Y_embed

Embeds the trajectory (or Vector) `Y` using the provided lags `τ`. If `Y` is a
dataset, a vector `ts` must be provided, which stores the indices of the time
series contained in `Y`, which needs to be used for each embedding cycle. Here
we enforce a causal embedding, meaning that we shift the time series `Y` (or any
of the time series in `Y`, if `Y` is a Dataset) by the negative values `τ` from
`τs`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.get_ar_prediction-Union{Tuple{T}, Tuple{Vector{T}, Vector{T} where T}} where T" href="#MCDTS.get_ar_prediction-Union{Tuple{T}, Tuple{Vector{T}, Vector{T} where T}} where T"><code>MCDTS.get_ar_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_ar_prediction(x::Vector, coeffs::Vector; kwargs...) → Y_predict

Computes a prediction `Y_predict` of the AR-model determined by the coefficients
in `coeffs`. The order of the AR-model equals the length of `coeffs`. `x` can be
a long vector (the time series), but needs to contain at least `length(coeffs)`
values, in order to initialize the model. If the time horizon `Tw` is larger than
1, an iterated one-step prediction is peformed.

Keywords:
* `Tw::Int = 1`: Time horizon for the prediction
* `c::Real = 0`: Offset-parameter for AR-model
* `rng::AbstractRNG = Random.GLOBAL_RNG`: Random number generator</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.get_binomial_table-Union{Tuple{T}, Tuple{T, T}} where T&lt;:Real" href="#MCDTS.get_binomial_table-Union{Tuple{T}, Tuple{T, T}} where T&lt;:Real"><code>MCDTS.get_binomial_table</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_binomial_table(p, α; trial_range::Int=8) -&gt; `δ_to_ε_amount`, Dict(δ_points =&gt; ϵ_points)</code></pre><p>compute the numbers of points from the δ-neighborhood, which need to fall outside the ϵ-neighborhood, in order to reject the Null Hypothesis at a significance level <code>α</code>. One parameter of the binomial distribution is <code>p</code>, the other one would be the number of trials, i.e. the considered number of points of the δ-neighborhood. <code>trial_range</code> determines the number of considered δ-neighborhood-points, always starting from 8. For instance, if <code>trial_range=8</code> (Default), then δ-neighborhood sizes from 8 up to 15 are considered. Return <code>δ_to_ε_amount</code>, a dictionary with <code>δ_points</code> as keys and the corresponding number of points in order to reject the Null, <code>ϵ_points</code>, constitute the values.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.get_delay_statistic-Tuple{MCDTS.Continuity_function, Any, Any, Any, Any, Any}" href="#MCDTS.get_delay_statistic-Tuple{MCDTS.Continuity_function, Any, Any, Any, Any, Any}"><code>MCDTS.get_delay_statistic</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_delay_statistic(optimalg.Λ&lt;: AbstractDelayPreselection, Ys, τs, w, τ_vals, ts_vals; kwargs... )

Compute the delay statistic according to the chosen method in `optimalg.Λ` (see [`MCDTSOptimGoal`](@ref))</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.get_embedding_params_according_to_loss-Tuple{MCDTS.AbstractLoss, Any, Any, Any, Any, Any}" href="#MCDTS.get_embedding_params_according_to_loss-Tuple{MCDTS.AbstractLoss, Any, Any, Any, Any, Any}"><code>MCDTS.get_embedding_params_according_to_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_embedding_params_according_to_loss(Γ::AbstractLoss, τ_pot, ts_popt, L_pot, L_old)

Helper function for [`get_potential_delays`](@ref). Computes the potential
delay-, time series- and according Loss-values with respect to the actual loss
in the current embedding cycle.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.get_max_idx-Union{Tuple{T}, Tuple{MCDTS.Range_function, Vector{T}, Any, Any, Any}} where T" href="#MCDTS.get_max_idx-Union{Tuple{T}, Tuple{MCDTS.Range_function, Vector{T}, Any, Any, Any}} where T"><code>MCDTS.get_max_idx</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_max_idx(Λ::AbstractDelayPreselection, dps::Vector, τ_vals, ts_vals) → max_idx

Compute the candidate delay values from the given delay pre-selection statistic
`dps` with respect to `Λ`, which determined how `dps` was obtained and how
to select the candidates (e.g. pick the maxima of `dps` in case of the
`Λ` being the Continuity function). See [`Continuity_function`](@ref) and
[`Range_function`](@ref).</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.get_maxima-Union{Tuple{Vector{T}}, Tuple{T}} where T" href="#MCDTS.get_maxima-Union{Tuple{Vector{T}}, Tuple{T}} where T"><code>MCDTS.get_maxima</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Return the local maxima of the given time series s and its indices</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.get_potential_delays-Union{Tuple{T}, Tuple{D}, Tuple{MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Any, Int64, Any, Any, Any}} where {D, T}" href="#MCDTS.get_potential_delays-Union{Tuple{T}, Tuple{D}, Tuple{MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Any, Int64, Any, Any, Any}} where {D, T}"><code>MCDTS.get_potential_delays</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_potential_delays(optimalg::AbstractMCDTSOptimGoal, Ys::Dataset, τs, w::Int, τ_vals,
                ts_vals, L_old ; kwargs...]) → τ_pot, ts_pot, L_pot, flag

Compute the potential delay `τ_pot` and time series values `ts_pot`, which would
each result in a potential Loss-statistic value `L_pot`, by using an
embedding method specified in `optimalg` [^Kraemer2021b] (see [`MCDTSOptimGoal`](@ref))
and for a range of possible delay values `τs`. The input dataset `Ys` can be
multivariate. `w` is the Theiler window (neighbors in time with index `w` close
to the point, that are excluded from being true neighbors. `w=0` means to
exclude only the point itself, and no temporal neighbors. In case of multivariate
time series input choose `w` as the maximum of all `wᵢ&#39;s`. `τ_vals` and `ts_vals`
describe the embedding up to the current embedding cycle.

## Keyword arguments
* See [`mcdts_embedding`](@ref) for a list of all keywords.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.integral_σ-Tuple{Any, Any}" href="#MCDTS.integral_σ-Tuple{Any, Any}"><code>MCDTS.integral_σ</code></a> — <span class="docstring-category">Method</span></header><section><div><p>approximately calculate ∫_0 ^(ξ) σ(ζ) dζ.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.iterated_local_linear_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64, Int64}} where {D, T}" href="#MCDTS.iterated_local_linear_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64, Int64}} where {D, T}"><code>MCDTS.iterated_local_linear_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">iterated_local_linear_prediction(Y::Dataset, K::Int = 5, Tw::Int = 2; kwargs...) → Y_predict

Perform an iterated one step forecast over `Tw` time steps using the local linear
prediction algorithm. `Y_predict` is a Dataset of length `Tw` and dimension like
`Y`.

Keywords:
* `metric = Euclidean()`: Metric used for distance computation
* `theiler::Int = 1`: Theiler window for excluding serially correlated points from
   the nearest neighbour search.
* `verbose::Bool = false`: When set to `true`, the function prints the actual time
  step, which it is computing.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.iterated_local_linear_prediction_embed-Union{Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T, Int64}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T, Int64, Int64}} where {D, T}" href="#MCDTS.iterated_local_linear_prediction_embed-Union{Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T, Int64}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T, Int64, Int64}} where {D, T}"><code>MCDTS.iterated_local_linear_prediction_embed</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">iterated_local_linear_prediction_embed(Y::Dataset, τs::Vector, K::Int = 5, Tw::Int = 2; kwargs...) → Y_predict
Perform an iterated one step forecast over `Tw` time steps using the local linear
prediction algorithm. `Y_predict` is a Dataset of length `Tw` and dimension like
`Y`. In contrast to `iterated_local_linear_prediction()` we here use the time
delays `τs` to reconstruct all components of a predicted trajectory point from
the 1st component, which is obtained from the local model. This only works for
univariate embeddings.

Keywords:
* `metric = Euclidean()`: Metric used for distance computation
* `theiler::Int = 1`: Theiler window for excluding serially correlated points from
   the nearest neighbour search.
* `verbose::Bool = false`: When set to `true`, the function prints the actual time
  step, which it is computing.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.iterated_local_zeroth_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64, Int64}} where {D, T}" href="#MCDTS.iterated_local_zeroth_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64, Int64}} where {D, T}"><code>MCDTS.iterated_local_zeroth_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">iterated_local_zeroth_prediction(Y::Dataset, K::Int = 5, Tw::Int = 2; kwargs...) → Y_predict</code></pre><p>Perform an iterated one step forecast over <code>Tw</code> time steps using the local zeroth prediction algorithm. <code>Y_predict</code> is a Dataset of length <code>Tw</code> and dimension like <code>Y</code>.</p><p>Keywords:</p><ul><li><code>metric = Euclidean()</code>: Metric used for distance computation</li><li><code>theiler::Int = 1</code>: Theiler window for excluding serially correlated points from  the nearest neighbour search.</li><li><code>verbose::Bool = false</code>: When set to <code>true</code>, the function prints the actual time step, which it is computing.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.iterated_local_zeroth_prediction_embed-Union{Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T, Int64}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T, Int64, Int64}} where {D, T}" href="#MCDTS.iterated_local_zeroth_prediction_embed-Union{Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T, Int64}, Tuple{DelayEmbeddings.Dataset{D, T}, Vector{T} where T, Int64, Int64}} where {D, T}"><code>MCDTS.iterated_local_zeroth_prediction_embed</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">iterated_local_zeroth_prediction_embed(Y::Dataset, τs::Vector, K::Int = 5, Tw::Int = 2; kwargs...) → Y_predict</code></pre><p>Perform an iterated one step forecast over <code>Tw</code> time steps using the local linear prediction algorithm. <code>Y_predict</code> is a Dataset of length <code>Tw</code> and dimension like <code>Y</code>. In contrast to <code>iterated_local_linear_prediction()</code> we here use the time delays <code>τs</code> to reconstruct all components of a predicted trajectory point from the 1st component, which is obtained from the local model. This only works for univariate embeddings.</p><p>Keywords:</p><ul><li><code>metric = Euclidean()</code>: Metric used for distance computation</li><li><code>theiler::Int = 1</code>: Theiler window for excluding serially correlated points from  the nearest neighbour search.</li><li><code>verbose::Bool = false</code>: When set to <code>true</code>, the function prints the actual time step, which it is computing.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.jrp_rr_frac-Tuple{RecurrenceAnalysis.RecurrenceMatrix, RecurrenceAnalysis.RecurrenceMatrix}" href="#MCDTS.jrp_rr_frac-Tuple{RecurrenceAnalysis.RecurrenceMatrix, RecurrenceAnalysis.RecurrenceMatrix}"><code>MCDTS.jrp_rr_frac</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Computes the similarity between recurrence plots `RP₁` and `RP₂`. Outputs the
fraction of recurrences rates gained from RP₁ and of the joint recurrence
plot `RP₁ .* RP₂`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.linear_prediction_cost-Union{Tuple{DelayEmbeddings.AbstractDataset{D, ET}}, Tuple{ET}, Tuple{D}} where {D, ET}" href="#MCDTS.linear_prediction_cost-Union{Tuple{DelayEmbeddings.AbstractDataset{D, ET}}, Tuple{ET}, Tuple{D}} where {D, ET}"><code>MCDTS.linear_prediction_cost</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">linear_prediction_cost(Y::Dataset; kwargs...) → Cost</code></pre><p>Compute the mean squared one-step prediction error <code>Cost</code> of the Dataset <code>Y</code>. The prediction is based on <a href="#MCDTS.local_linear_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}} where {D, T}"><code>local_linear_prediction</code></a>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>samplesize = 1.0</code>: Number of considered fiducial points v as a fraction of input state space trajectory <code>Y</code>&#39;s length, in order to average the conditional variances and neighborhood sizes (read algorithm description) to produce <code>L</code>.</li><li><code>K = 3</code>: the amount of nearest neighbors considered, in order to compute the mean squared prediction error (read algorithm description).</li><li><code>metric = Euclidean()</code>: metric used for finding nearest neigbhors in the input state space trajectory `Y.</li><li><code>w = 1</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors.</li><li><code>Tw = 1</code>: The time horizon for predictions. The <code>Cost</code> is the average error over these timesteps.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.linear_prediction_cost_KL-Union{Tuple{DelayEmbeddings.AbstractDataset{D, ET}}, Tuple{ET}, Tuple{D}} where {D, ET}" href="#MCDTS.linear_prediction_cost_KL-Union{Tuple{DelayEmbeddings.AbstractDataset{D, ET}}, Tuple{ET}, Tuple{D}} where {D, ET}"><code>MCDTS.linear_prediction_cost_KL</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">linear_prediction_cost_KL(Y::Dataset; kwargs...) → Cost</code></pre><p>Compute the KL-divergence <code>Cost</code> of the Dataset <code>Y</code>. The prediction is based on <a href="#MCDTS.local_linear_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}} where {D, T}"><code>local_linear_prediction</code></a>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>samplesize = 1.0</code>: Number of considered fiducial points v as a fraction of input state space trajectory <code>Y</code>&#39;s length, in order to average the conditional variances and neighborhood sizes (read algorithm description) to produce <code>L</code>.</li><li><code>K = 3</code>: the amount of nearest neighbors considered, in order to compute the mean squared prediction error (read algorithm description).</li><li><code>metric = Euclidean()</code>: metric used for finding nearest neigbhors in the input state space trajectory `Y.</li><li><code>w = 1</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors.</li><li><code>Tw = 1</code>: The time horizon for predictions. The <code>Cost</code> is the average error over these timesteps.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.local_linear_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}} where {D, T}" href="#MCDTS.local_linear_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}} where {D, T}"><code>MCDTS.local_linear_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">local_linear_prediction(Y::Dataset, K::Int = 5; kwargs...) → x_pred, e_expect

Perform a prediction for the time horizon `Tw` (default = 1) by a locally linear
fit. Based on `K` nearest neighbours of the last point of the given trajectory
`Y`, we fit a linear model to these points and their `Tw`-step ahead images. The
output `x_pred` is, thus, the `Tw`-step ahead prediction vector.
The function also returns `e_expect`, the expected error on the prediction `x_pred`,
computed as the mean of the RMS-errors of all `K`-neighbours-errors.

Keywords:
* `metric = Euclidean()`: Metric used for distance computation
* `theiler::Int = 1`: Theiler window for excluding serially correlated points from
   the nearest neighbour search.
* `Tw::Int = 1`: The prediction time in sampling units. If `Tw &gt; 1`, a multi-step
  prediction is performed.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.local_random_analogue_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}} where {D, T}" href="#MCDTS.local_random_analogue_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}} where {D, T}"><code>MCDTS.local_random_analogue_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">local_random_analogue_prediction(Y::Dataset, K::Int; kwargs...) → Y_predict</code></pre><p>Compute a one step ahead prediction <code>Y_predict</code> of the input <code>Y</code>, based on <code>K</code> nearest neighbors. Here the prediction is a random pick from all <code>K</code>-nearest neighbour images and, thus, invokes some kind of randomness.</p><p>Keywords:</p><ul><li><code>metric = Euclidean()</code>: Metric used for distance computation</li><li><code>theiler::Int = 1</code>: Theiler window for excluding serially correlated points from  the nearest neighbour search.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.local_zeroth_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}} where {D, T}" href="#MCDTS.local_zeroth_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}} where {D, T}"><code>MCDTS.local_zeroth_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">local_zeroth_prediction(Y::Dataset, K::Int = 5; kwargs...) → x_pred, e_expect</code></pre><p>Perform a &quot;zeroth&quot; order prediction for the time horizon <code>Tw</code> (default = 1). Based on <code>K</code> nearest neighbours of the last point of the given trajectory <code>Y</code>, the <code>Tw</code>-step ahead prediction is simply the mean of the images of these <code>K</code>-nearest neighbours. The output <code>x_pred</code> is, thus, the <code>Tw</code>-step ahead prediction vector. The function also returns <code>e_expect</code>, the expected error on the prediction <code>x_pred</code>, computed as the mean of the RMS-errors of all <code>K</code>-neighbours-errors.</p><p>Keywords:</p><ul><li><code>metric = Euclidean()</code>: Metric used for distance computation</li><li><code>theiler::Int = 1</code>: Theiler window for excluding serially correlated points from  the nearest neighbour search.</li><li><code>Tw::Int = 1</code>: The prediction time in sampling units. If <code>Tw &gt; 1</code>, a multi-step prediction is performed.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.make_prediction-Union{Tuple{ET}, Tuple{D}, Tuple{MCDTS.AbstractPredictionMethod{:zeroth}, DelayEmbeddings.AbstractDataset{D, ET}}} where {D, ET}" href="#MCDTS.make_prediction-Union{Tuple{ET}, Tuple{D}, Tuple{MCDTS.AbstractPredictionMethod{:zeroth}, DelayEmbeddings.AbstractDataset{D, ET}}} where {D, ET}"><code>MCDTS.make_prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">make_prediction(pred_meth::AbstractPredictionMethod, Y::AbstractDataset{D, ET};
        K::Int = 3, w::Int = 1, Tw::Int = 1, metric = Euclidean()) → prediction

Compute a in-sample `Tw`-time-steps-ahead of the data `Y`, using the prediction
method `pred_meth`. `w` is the Theiler window and `K` the nearest neighbors used.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.mc_delay-Tuple" href="#MCDTS.mc_delay-Tuple"><code>MCDTS.mc_delay</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Legacy name, please use [`mcdts_embedding`](@ref)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.mcdts_embedding-Union{Tuple{D}, Tuple{DelayEmbeddings.Dataset, MCDTS.AbstractMCDTSOptimGoal, Int64, AbstractRange{D}}, Tuple{DelayEmbeddings.Dataset, MCDTS.AbstractMCDTSOptimGoal, Int64, AbstractRange{D}, Int64}} where D" href="#MCDTS.mcdts_embedding-Union{Tuple{D}, Tuple{DelayEmbeddings.Dataset, MCDTS.AbstractMCDTSOptimGoal, Int64, AbstractRange{D}}, Tuple{DelayEmbeddings.Dataset, MCDTS.AbstractMCDTSOptimGoal, Int64, AbstractRange{D}, Int64}} where D"><code>MCDTS.mcdts_embedding</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mcdts_embedding

## Convenience / default option call

mcdts_embedding(data::Dataset, N::Int=100; kwargs...)

Do the MCDTS embedding of the `data` with `N` trials according to the
PECUZAL algorithm [^Kraemer2021], returns the tree. Embedding parameters
like the Theiler window, considered delays and the function that chooses the
next embedding step are all estimated automatically or the default option is
used. `data` is a `DynamicalSystems.Dataset`.

## All options

mcdts_embedding(data::DynamicalSystems.Dataset, optimalg::AbstractMCDTSOptimGoal,
                        w::Int, delays::AbstractRange{D}, N::Int=40;  kwargs...)

* `optimalg::AbstractMCDTSOptimGoal` determines how the embedding is performed in
  each cycle. Specifically it sets the delay pre-selection statistic Λ, which
  pre-selects the potential delays in each embedding cycle as well as the the
  Loss-Statistic Γ, which determines the Loss to be minimized by MCDTS
  [^Kraemer2021b] (see [`MCDTSOptimGoal`](@ref)).
* `w` is the Theiler window (neighbors in time with index `w` close to the point,
  that are excluded from being true neighbors. `w=0` means to exclude only the
  point itself, and no temporal neighbors. In case of multivariate time series
  input choose `w` as the maximum of all `wᵢ&#39;s`. As a default in the convience
  call this is estimated with a mutual information minimum method of DelayEmbeddings.jl
* `delays = 0:100`: The possible time lags
* `N::Int`: The number of tree expansions

## Keyword Arguments
* `choose_func`: Function to choose next node in the tree with, default
  choice: `(L)-&gt;(MCDTS.softmaxL(L,β=2.))`
* `max_depth = 20`: Threshold, which determines the algorithm. It either breaks,
  when it converges, i.e. when there is no way to reduce the cost-function any
  further, or when this threshold is reached.
* `verbose`: Either `true` or `false` (default); prints status of embedding optimization.
* `metric`: norm for distance computation (default is `Euclidean()`)






* `KNN = 3`: The number of nearest neighbors considered in the computation of
  the L-statistic.
* `FNN:Bool = false`: Determines whether the algorithm should minimize the
  L-statistic or the FNN-statistic.
* `PRED::Bool = false`: Determines whether the algorithm should minimize the
  L-statistic or a cost function based on minimizing the `Tw`-step-prediction error
* `Tw::Int = 1`: If `PRED = true`, this is the considered prediction horizon
* `linear::Bool=false`: If `PRED = true`, this determines whether the prediction shall
  be made on the zeroth or a linear predictor.
* `PRED_mean::Bool=false`: If `PRED = true`, this determines whether the prediction shall
  be optimized on the mean MSE of all components or only on the 1st-component (Default)
* `PRED_L::Bool=false`: If `PRED = true`, this determines whether the prediction shall
  be optimized on possible delay values gained from the continuity statistic or on
  delays = 0:25 (Default)
* `PRED_KL::Bool=false`: If `PRED = true`, this determines whether the prediction shall
  be optimized on the Kullback-Leibler-divergence of the in-sample prediction and
  the true in-sample values, or if the optimization shall be made on the MSE of them (Default)
* `CCM:Bool=false`: Determines whether the algorithm should maximize the CCM-correlation
  coefficient of the embedded vector from `Ys` and the given time series `Y_CCM`.
* `Y_CCM`: The time series CCM should cross map to.
* `threshold::Real = 0`: The algorithm does not pick a peak from the continuity
  statistic, when its corresponding `ΔL`/FNN-value exceeds this threshold. Please
  provide a positive number for both, `L` and `FNN`-statistic option (since the
  `ΔL`-values are negative numbers for meaningful embedding cycles, this threshold
  gets internally sign-switched).
* `tws::Range = 2:delays[end]`: Customization of the sampling of the different T&#39;s,
  when computing Uzal&#39;s L-statistics. Here any kind of integer ranges (starting
  at 2) are allowed, up to `delays[end]`.

  [^Kraemer2021]: Kraemer, K.H., Datseris, G., Kurths, J., Kiss, I.Z., Ocampo-Espindola, Marwan, N. (2021). [A unified and automated approach to attractor reconstruction. New Journal of Physics 23(3), 033017](https://iopscience.iop.org/article/10.1088/1367-2630/abe336).
  [^Kraemer2021b]: Kraemer, K.H., Gelbrecht, M., Pavithran, I., Sujith, R. I. and Marwan, N. (2021). [Optimal state space reconstruction via Monte Carlo Decision Tree Search. Submitted to Nonlinear Dynamics](https://doi.org/10.21203/rs.3.rs-899760/v1)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.mfnn-Tuple{DelayEmbeddings.Dataset, DelayEmbeddings.Dataset}" href="#MCDTS.mfnn-Tuple{DelayEmbeddings.Dataset, DelayEmbeddings.Dataset}"><code>MCDTS.mfnn</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Computes the mututal false nearest neighbours (mfnn) for a reference trajectory
`Y_ref` and a reconstruction `Y_rec` after [^Rulkov1995].

## Keyword arguments
*`w = 1`: Theiler window for the surpression of serially correlated neighbors in
    the nearest neighbor-search
*`kNN = 1`: The number of considered nearest neighbours (in the paper always 1)

[^Rulkov1995]: Rulkov, Nikolai F. and Sushchik, Mikhail M. and Tsimring, Lev S. and Abarbanel, Henry D.I. (1995). [Generalized synchronization of chaos in directionally coupled chaotic systems. Physical Review E 51, 980](https://doi.org/10.1103/PhysRevE.51.980).</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.moving_average-Tuple{Any, Any}" href="#MCDTS.moving_average-Tuple{Any, Any}"><code>MCDTS.moving_average</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Moving average of a timeseries `vs` over a window `n`</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.next_embedding-Union{Tuple{T}, Tuple{D}, Tuple{MCDTS.Node, MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Int64, Any}} where {D, T&lt;:Real}" href="#MCDTS.next_embedding-Union{Tuple{T}, Tuple{D}, Tuple{MCDTS.Node, MCDTS.AbstractMCDTSOptimGoal, DelayEmbeddings.Dataset{D, T}, Int64, Any}} where {D, T&lt;:Real}"><code>MCDTS.next_embedding</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">next_embedding(n::Node, optimalg::AbstractMCDTSOptimGoal, Ys::Dataset{D, T},
                        w::Int, τs; kwargs...) → τ_pot, ts_pot, L_pot, flag

Performs the next embedding step. For the actual embedding contained in tree
leaf `n` compute as many statistics determined by `optimalg.Λ`
(see [`MCDTSOptimGoal`](@ref)) as there are time series in the Dataset
`Ys` for a range of possible delays `τs`. Return the values for the best delay
`τ_pot`, its corresponding time series index `ts_pot` the according Loss-value
`L_pot` and `flag`, following the minimization of the Loss determined by
`optimalg.Γ`.

## Keyword arguments
* See [`mcdts_embedding`](@ref) for a list of all keywords.

## Returns
* `τ_pot`: Next delay
* `ts_pot`: Index of the time series used (in case of multivariate time series)
* `L_pot`: L statistic of next embedding step with delay `τ_pot` from `ts_pot`.
* `flag`: Did the embedding converge? i.e. L can not be further minimized anymore</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.nonlin_noise_reduction-Union{Tuple{T}, Tuple{Vector{T}, Int64, Int64}} where T" href="#MCDTS.nonlin_noise_reduction-Union{Tuple{T}, Tuple{Vector{T}, Int64, Int64}} where T"><code>MCDTS.nonlin_noise_reduction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Simple nonlinear noise reduction algorithm by Schreiber 1993

Params:
*`m`           denotes the local embedding dimension
*`epsilon`     denotes the local neighborhood size as number of neighbours

Returns:
the filtered signal

Note that by applying this filter, there will be lost `m-1` datapoints.
We therefore phase-shift each datapoint in the resulting signal by `(m-1)/2`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.pecora-Union{Tuple{T}, Tuple{D}, Tuple{Any, Tuple{Vararg{Int64, D}}}, Tuple{Any, Tuple{Vararg{Int64, D}}, Tuple{Vararg{Int64, D}}}} where {D, T&lt;:Real}" href="#MCDTS.pecora-Union{Tuple{T}, Tuple{D}, Tuple{Any, Tuple{Vararg{Int64, D}}}, Tuple{Any, Tuple{Vararg{Int64, D}}, Tuple{Vararg{Int64, D}}}} where {D, T&lt;:Real}"><code>MCDTS.pecora</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">pecora(s, τs, js; kwargs...) → ⟨ε★⟩, ⟨Γ⟩</code></pre><p>Compute the (average) continuity statistic <code>⟨ε★⟩</code> and undersampling statistic <code>⟨Γ⟩</code> according to Pecora et al.<sup class="footnote-reference"><a id="citeref-Pecoral2007" href="#footnote-Pecoral2007">[Pecoral2007]</a></sup> (A unified approach to attractor reconstruction), for a given input <code>s</code> (timeseries or <code>Dataset</code>) and input generalized embedding defined by <code>(τs, js)</code>, according to <a href="@ref"><code>genembed</code></a>. The continuity statistic represents functional independence between the components of the existing embedding and one additional timeseries. The returned results are <em>matrices</em> with size <code>T</code>x<code>J</code>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>delays = 0:50</code>: Possible time delay values <code>delays</code> (in sampling time units). For each of the <code>τ</code>&#39;s in <code>delays</code> the continuity-statistic <code>⟨ε★⟩</code> gets computed. If <code>undersampling = true</code> (see further down), also the undersampling statistic <code>⟨Γ⟩</code> gets returned for all considered delay values.</li><li><code>J = 1:dimension(s)</code>: calculate for all timeseries indices in <code>J</code>. If input <code>s</code> is a timeseries, this is always just 1.</li><li><code>samplesize::Real = 0.1</code>: determine the fraction of all phase space points (=<code>length(s)</code>) to be considered (fiducial points v) to average ε★ to produce <code>⟨ε★⟩, ⟨Γ⟩</code></li><li><code>K::Int = 13</code>: the amount of nearest neighbors in the δ-ball (read algorithm description). Must be at least 8 (in order to gurantee a valid statistic). <code>⟨ε★⟩</code> is computed taking the minimum result over all <code>k ∈ K</code>.</li><li><code>metric = Chebyshev()</code>: metrix with which to find nearest neigbhors in the input embedding (ℝᵈ space, <code>d = length(τs)</code>).</li><li><code>w = 1</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors.</li><li><code>undersampling = false</code> : whether to calculate the undersampling statistic or not (if not, zeros are returned for <code>⟨Γ⟩</code>). Calculating <code>⟨Γ⟩</code> is thousands of times slower than <code>⟨ε★⟩</code>.</li><li><code>db::Int = 100</code>: Amount of bins used into calculating the histograms of each timeseries (for the undersampling statistic).</li><li><code>α::Real = 0.05</code>: The significance level for obtaining the continuity statistic</li><li><code>p::Real = 0.5</code>: The p-parameter for the binomial distribution used for the computation of the continuity statistic.</li></ul><p><strong>Description</strong></p><p>Notice that the full algorithm is too large to discuss here, and is written in detail (several pages!) in the source code of <code>pecora</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.perform_recurrence_analysis-NTuple{4, DelayEmbeddings.Dataset}" href="#MCDTS.perform_recurrence_analysis-NTuple{4, DelayEmbeddings.Dataset}"><code>MCDTS.perform_recurrence_analysis</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Perform the RecurrenceAnalysis of some reconstruction trajectories `Y₁`, `Y₂`,
`Y₃`. Specifically, compute the fraction of recurrence rates from the
&quot;original&quot;/reference trajectory `Y_ref` with the one from the JRP of the
original `Y₁`, `Y₂`, `Y₃` together with the reconstructed trajectory. Also
compute RQA quantifiers of the recurrence plots of `Y₁`, `Y₂`, `Y₃` and `Y_ref`.

## Keyword arguments:
*`ε = 0.05`: The used threshold for constructing the recurrence plots
    The reconstruction method is fixed recurrence rate.
*`w = 1`: Theiler window used for all Datasets
*`lmin = 2`: Minimum used line length for digaonal line based RQA measures.
*`kNN = 1`: The number of nearest neighbors used for obtaining the mutual
    nearest neighbors measure</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.pick_possible_embedding_params-Union{Tuple{T}, Tuple{D}, Tuple{MCDTS.AbstractLoss, MCDTS.AbstractDelayPreselection, Any, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Any, Any}} where {D, T}" href="#MCDTS.pick_possible_embedding_params-Union{Tuple{T}, Tuple{D}, Tuple{MCDTS.AbstractLoss, MCDTS.AbstractDelayPreselection, Any, DelayEmbeddings.Dataset{D, T}, Any, Any, Int64, Any, Any}} where {D, T}"><code>MCDTS.pick_possible_embedding_params</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Compute all possible τ-values (and according time series numbers) and their
corresponding Loss-statistics for the input delay_pre_selection_statistic `dps`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.rw_norm-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T" href="#MCDTS.rw_norm-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T"><code>MCDTS.rw_norm</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Compute the scaling term for the MASE measure. This is tge average in-sample
forecast error for a random-walk prediction, which uses the previous value in
the observed signal `x` as the forecast. `Tw` is the prediction time horizon.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.softmaxL-Tuple{Any}" href="#MCDTS.softmaxL-Tuple{Any}"><code>MCDTS.softmaxL</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">softmaxL(Ls; β=1.5)

Returns an index with prob computed by a softmax of all Ls.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.uzal_cost_pecuzal_mcdts-Union{Tuple{ET}, Tuple{DT}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, ET}, DelayEmbeddings.Dataset{DT, ET}, Int64}} where {D, DT, ET}" href="#MCDTS.uzal_cost_pecuzal_mcdts-Union{Tuple{ET}, Tuple{DT}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, ET}, DelayEmbeddings.Dataset{DT, ET}, Int64}} where {D, DT, ET}"><code>MCDTS.uzal_cost_pecuzal_mcdts</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">uzal_cost_pecuzal_mcdts(Y1::Dataset, Y2::Dataset, Tw; kwargs...) → L_decrease

This function is based on the functionality of [`uzal_cost`](@ref), here
specifically tailored for the needs in the PECUZAL algorithm.
Compute the L-statistics `L1` and `L2` for the input datasets `Y1` and `Y2` for
increasing time horizons `T = 1:Tw`. For each `T`, compute `L1` and `L2` and
decrease `L_decrease = L2 - L1`. If `L_decrease` is a negative value, then `Y2`
can be regarded as a &quot;better&quot; reconstruction that `Y1`. Break, when `L_decrease`
reaches the 1st local minima, since this will typically also be the global
minimum. Return the according minimum `L_decrease`-value.

## Keyword arguments

* `K = 3`: the amount of nearest neighbors considered, in order to compute σ_k^2
  (read algorithm description).
  If given a vector, minimum result over all `k ∈ K` is returned.
* `metric = Euclidean()`: metric used for finding nearest neigbhors in the input
  state space trajectory `Y.
* `w = 1`: Theiler window (neighbors in time with index `w` close to the point,
  that are excluded from being true neighbors). `w=0` means to exclude only the
  point itself, and no temporal neighbors.
* `econ::Bool = false`: Economy-mode for L-statistic computation. Instead of
  computing L-statistics for time horizons `2:Tw`, here we only compute them for
  `2:2:Tw`.
* `tws::Range = 2:Tw`: Further customization of the sampling of the different T&#39;s.
  While `econ=true` gives `tws = 2:2:Tw`, here any kind of interger ranges (starting at 2)
  are allowed, up to `Tw`.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.zeroth_prediction_cost-Union{Tuple{DelayEmbeddings.AbstractDataset{D, ET}}, Tuple{ET}, Tuple{D}} where {D, ET}" href="#MCDTS.zeroth_prediction_cost-Union{Tuple{DelayEmbeddings.AbstractDataset{D, ET}}, Tuple{ET}, Tuple{D}} where {D, ET}"><code>MCDTS.zeroth_prediction_cost</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">zeroth_prediction_cost(Y::Dataset; kwargs...) → Cost

Compute the mean squared one-step prediction error `Cost` of the Dataset `Y`.
The prediction is based on [`local_zeroth_prediction`](@ref).

## Keyword arguments

* `samplesize = 1.0`: Number of considered fiducial points v as a fraction of
  input state space trajectory `Y`&#39;s length, in order to average the conditional
  variances and neighborhood sizes (read algorithm description) to produce `L`.
* `K = 3`: the amount of nearest neighbors considered, in order to compute the
  mean squared prediction error (read algorithm description).
* `metric = Euclidean()`: metric used for finding nearest neigbhors in the input
  state space trajectory `Y.
* `w = 1`: Theiler window (neighbors in time with index `w` close to the point,
  that are excluded from being true neighbors). `w=0` means to exclude only the
  point itself, and no temporal neighbors.
* `Tw = 1`: The time horizon for predictions. The `Cost` is the average error
  over these timesteps.</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MCDTS.zeroth_prediction_cost_KL-Union{Tuple{DelayEmbeddings.AbstractDataset{D, ET}}, Tuple{ET}, Tuple{D}} where {D, ET}" href="#MCDTS.zeroth_prediction_cost_KL-Union{Tuple{DelayEmbeddings.AbstractDataset{D, ET}}, Tuple{ET}, Tuple{D}} where {D, ET}"><code>MCDTS.zeroth_prediction_cost_KL</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">zeroth_prediction_cost_KL(Y::Dataset; kwargs...) → Cost</code></pre><p>Compute the KL-divergence <code>Cost</code> of the Dataset <code>Y</code>. The prediction is based on <a href="#MCDTS.local_zeroth_prediction-Union{Tuple{DelayEmbeddings.Dataset{D, T}}, Tuple{T}, Tuple{D}, Tuple{DelayEmbeddings.Dataset{D, T}, Int64}} where {D, T}"><code>local_zeroth_prediction</code></a>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>samplesize = 1.0</code>: Number of considered fiducial points v as a fraction of input state space trajectory <code>Y</code>&#39;s length, in order to average the conditional variances and neighborhood sizes (read algorithm description) to produce <code>L</code>.</li><li><code>K = 3</code>: the amount of nearest neighbors considered, in order to compute the mean squared prediction error (read algorithm description).</li><li><code>metric = Euclidean()</code>: metric used for finding nearest neigbhors in the input state space trajectory `Y.</li><li><code>w = 1</code>: Theiler window (neighbors in time with index <code>w</code> close to the point, that are excluded from being true neighbors). <code>w=0</code> means to exclude only the point itself, and no temporal neighbors.</li><li><code>Tw = 1</code>: The time horizon for predictions. The <code>Cost</code> is the average error over these timesteps.</li></ul></div></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Pecora2007"><a class="tag is-link" href="#citeref-Pecora2007">Pecora2007</a>Pecora, L. M., Moniz, L., Nichols, J., &amp; Carroll, T. L. (2007). <a href="https://doi.org/10.1063/1.2430294">A unified approach to attractor reconstruction. Chaos 17(1)</a>.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 22 November 2021 17:53">Monday 22 November 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
